# Now you see me
Innoative and lightweight software that assists the visually impaired in 
navigating outdoors in realtime without relying on the Internet. It uniquely 
combines both depth and RGB technologies to give the most detailed perception
possible (mirroring how our own eyes work). It was built and tested on the 
Microsoft Kinect V2 and V1, but it can be made to work with any RGB-D camera.

The depth-based blob detection is written in C++ while the object detection is 
written in Python using the OpenCV library. Before you test it out, make sure you
unzip opencv_world411d.dll.zip. I had to compress it to meet Github's indiviudal
file size policy!
